# Machine Learning

## Universal Sentence Encoder and Embeddings

- ğŸ“• [Understanding word vectors](https://gist.github.com/aparrish/2f562e3737544cf29aaf1af30362f469)
- ğŸ¿ [What is word2vec](https://youtu.be/LSS_bos_TPI), [Color Vectors](https://youtu.be/mI23bDF0VRI)
- ğŸ“š [2018 Universal Sentence Encoder paper](https://arxiv.org/abs/1803.11175)
- ğŸ’» [Universal Sentence Encoder - tensorflow.js](https://github.com/tensorflow/tfjs-models/tree/master/universal-sentence-encoder)
- ğŸ’» [Universal Sentence Encoder ml5 + p5](https://editor.p5js.org/a2zitp/sketches/pjV49ct_B)

## Recurrent Neural Networks

- ğŸ“š [The Unreasonable Effectiveness of RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) and [Visualizing and Understanding Recurrent Networks](https://skillsmatter.com/skillscasts/6611-visualizing-and-understanding-recurrent-networks) by by Andrei Karpathy
- ğŸ“š [Rohan & Lenny #3: Recurrent Neural Networks & LSTMs](https://ayearofai.com/rohan-lenny-3-recurrent-neural-networks-10300100899b)
- ğŸ“š [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) by Christopher Olah
- ğŸ¿ [Sunspring](https://arstechnica.com/gaming/2016/06/an-ai-wrote-this-movie-and-its-strangely-moving/)
- ğŸ¨ [Double Agent](http://littlepig.org.uk/installations/doubleagent/index.htm) by Simon Biggs (Drawing)
- ğŸ¨ [Four Experiments in Handwriting with a Neural Network](https://distill.pub/2016/handwriting/) (Drawing)
- ğŸ“– [10 things artificial intelligence did in 2018](http://aiweirdness.com/post/181621835642/10-things-artificial-intelligence-did-in-2018) by Janelle Shane (Text)
- ğŸ“– [Writing with the Machine](https://www.robinsloan.com/notes/writing-with-the-machine/)
- ğŸ“‹ [ml5 charRNN reference](https://learn.ml5js.org/#/reference/charrnn), ğŸ’» [ml5 charRNN examples](https://learn.ml5js.org/#/reference/charrnn?id=examples), ğŸ’» [ml5 charRNN training in colab](https://colab.research.google.com/drive/1V1xJfHfoG0UrI4Og3sE4kG2De1gLg0NK), [training-charRNN repo](https://github.com/ml5js/training-charRNN)
- ğŸ¿ [Interactive Drawing with SketchRNN](https://youtu.be/ZCXkvwLxBrA)

## GPT

> among the reasons I use large pre-trained language models sparingly in my computer-generated poetry practice is that being able to know whose voices I'm speaking with is... actually important, as is being understanding how the output came to have its shape - [@aparrish](https://twitter.com/aparrish/)

- ğŸ“• [Allison Parrish Large Language Model Tweet Thread](https://twitter.com/aparrish/status/1286808606466244608)
- ğŸ¿ [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ğŸ¦œ](https://dl.acm.org/doi/10.1145/3442188.3445922)
- ğŸ¿ [Generative Text Training with GPT-2](https://youtu.be/-v5StaeOisM) from RunwayML
- ğŸ¿ [AI Language Models & Transformers - Computerphile](https://youtu.be/rURRYI66E54)
- ğŸ“š [The Next Word: Where will predictive text take us?](https://www.newyorker.com/magazine/2019/10/14/can-a-machine-learn-to-write-for-the-new-yorker)
- ğŸ“š [The Supply of Disinformation Will Soon Be Infinite](https://www.theatlantic.com/ideas/archive/2020/09/future-propaganda-will-be-computer-generated/616400)
- ğŸ’» [GPT-2 RunwayML + p5.js template on Glitch](https://glitch.com/edit/#!/runway-ml-gpt-api)
- ğŸ’» [Hugging Face](https://huggingface.co/)
  - ğŸ“‹ [Inference API for Text Generations](https://api-inference.huggingface.co/docs/python/html/detailed_parameters.html#text-generation-task)
  - ğŸ“‹ [Model Hub](https://huggingface.co/models)
  - ğŸ’» [node.js + p5 Hugging Face example code](https://github.com/Programming-from-A-to-Z/Hugging-Face-API-F21)

## Text to Images AI

Reading list thanks to [@advadnoun](https://twitter.com/advadnoun)!

- ğŸ“• [A brief history of the CLIP art scene](https://ml.berkeley.edu/blog/posts/clip-art/)
- ğŸ“š [Feature Visualization](https://distill.pub/2017/feature-visualization/)
- ğŸ“š [Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- ğŸ“š [OpenAI CLIP blog post](https://openai.com/blog/clip/)
- ğŸ“š [Taming Transformers VQGAN blog post](https://compvis.github.io/taming-transformers/)
- ğŸ’» [The Big Sleep BigGANxCLIP](https://colab.research.google.com/github/levindabhi/CLIP-Notebooks/blob/main/The_Big_Sleep_BigGANxCLIP.ipynb)
- ğŸ’» [Aleph-Image: CLIPxDAll-E](https://colab.research.google.com/drive/1Q-TbYvASMPRMXCOQjkxxf72CXYjR_8Vp?usp=sharing)

## Emoji Key for Video Tutorials, Readings, and more

- ğŸš¨ Watch this video tutorial! (this is technical info needed for the examples). Of course if you already know this material, you can skip.
- ğŸ”¢ This is found in a group, maybe pick just one to check out!
- ğŸ¿ Additional video if you have a particular interest and want to do a deeper dive.
- ğŸ“• Required reading! Let's make sure we all have read this.
- ğŸ“š Optional additional reading for a deeper dive.
- ğŸ’» Code examples here!
- ğŸ“ˆ Class presentation slides
- ğŸ”— Extra reference material / link
